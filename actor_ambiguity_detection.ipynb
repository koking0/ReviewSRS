{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户故事角色歧义检测分析\n",
    "\n",
    "本notebook用于分析大模���在检测用户故事角色歧义方面的性能。\n",
    "\n",
    "## 角色歧义定义\n",
    "角色歧义是指用户故事中的角色（actor）不明确或不清晰，导致对功能的执行者、受益者或相关方产生理解偏差。例如：\n",
    "- 角色定义模糊或不具体\n",
    "- 存在多个可能的执行者\n",
    "- 角色权限和职责不明确\n",
    "- 缺乏对角色的具体描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置信息\n",
    "CONFIG = {\n",
    "    \"base_url\": \"https://api.zhizengzeng.com/v1/\",\n",
    "    \"api_key\": \"sk-zk20f741becece1c055c848225093b2e458662329a0f1016\"\n",
    "}\n",
    "\n",
    "# 模型列表\n",
    "MODELS = [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"claude-sonnet-4-20250514\", \n",
    "    \"gemini-2.5-flash\",\n",
    "    \"grok-3-mini\",\n",
    "    \"deepseek-chat\",\n",
    "    \"qwen3-coder-plus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "print(\"Loading user story ambiguity dataset...\")\n",
    "df = pd.read_excel(r\"data/User Story Ambiguity Dataset_A Comprehensive Research Resource/Cornelius_2025_user_story_ambiguity_dataset.xlsx\", sheet_name='User_Stories')\n",
    "\n",
    "print(f\"数据集形状: {df.shape}\")\n",
    "print(f\"角色歧义统计: {df['ActorAmbiguity'].value_counts()}\")\n",
    "\n",
    "# 显示一些例子\n",
    "print(\"\\n角色歧义示例:\")\n",
    "actor_examples = df[df['ActorAmbiguity'] == True][['StoryText']].head(3)\n",
    "for i, story in enumerate(actor_examples['StoryText'], 1):\n",
    "    print(f\"{i}. {story}\")\n",
    "\n",
    "print(\"\\n无角色歧义示例:\")\n",
    "non_actor_examples = df[df['ActorAmbiguity'] == False][['StoryText']].head(3)\n",
    "for i, story in enumerate(non_actor_examples['StoryText'], 1):\n",
    "    print(f\"{i}. {story}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_ambiguity_prompt(story_text: str) -> str:\n",
    "    \"\"\"\n",
    "    生成用于检测用户故事角色歧义的提示词\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "**背景**: 角色歧义是指用户故事中的角色（actor）不明确或不清晰，导致对功能的执行者、受益者或相关方产生理解偏差。\n",
    "\n",
    "**角色**: 你是一名专业的自然语言处理专家，专门检测软件需求规格中的角色歧义。\n",
    "\n",
    "**任务**: 分析以下用户故事，判断其中是否存在角色歧义。\n",
    "\n",
    "**角色歧义的特征包括**:\n",
    "1. 角色定义模糊或不具体（如\"用户\"、\"相关人员\"等过于宽泛的表述）\n",
    "2. 存在多个可能的执行者或受益者\n",
    "3. 角色权限和职责不明确\n",
    "4. 缺乏对角色的具体描述或特征\n",
    "5. 角色与功能的关系不清晰\n",
    "6. 使用代词指代角色但不明确具体指谁\n",
    "7. 角色身份在业务流程中不明确\n",
    "8. 多个角色之间的权限边界模糊\n",
    "\n",
    "**用户故事**: {story_text}\n",
    "\n",
    "**输出要求**:\n",
    "请按照以下JSON格式输出你的分析结果：\n",
    "{{\n",
    "    \"has_actor_ambiguity\": true/false,\n",
    "    \"ambiguity_explanation\": \"如果存在角色歧义，请解释歧义的具体内容和角色不明确的地方；如果不存在角色歧义，请说明为什么用户故事的角色是清晰的\",\n",
    "    \"identified_actors\": \"列出用户故事中识别出的角色，如果存在歧义请说明哪些角色不明确\",\n",
    "    \"role_clarification_needed\": \"如果存在歧义，请说明需要澄清的角色信息；如果不存在歧义，请说明角色定义已经清晰的部分\",\n",
    "    \"suggested_improvement\": \"如果存在角色歧义，请提出改进建议；如果不存在角色歧义，请填写'无角色歧义，无需改进'\"\n",
    "}}\n",
    "\n",
    "**注意事项**:\n",
    "- has_actor_ambiguity的值只能是true或false\n",
    "- ambiguity_explanation应详细说明角色歧义的原因\n",
    "- identified_actors应明确指出识别的角色\n",
    "- role_clarification_needed应指出需要澄清的具体角色信息\n",
    "- suggested_improvement应提供具体的改进建议\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str, model: str) -> Dict:\n",
    "    \"\"\"\n",
    "    调用大模型API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(api_key=CONFIG[\"api_key\"], base_url=CONFIG[\"base_url\"])\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # 尝试解析JSON格式的响应\n",
    "        match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group()\n",
    "            parsed_result = json.loads(json_str)\n",
    "            return parsed_result\n",
    "        else:\n",
    "            # 如果无法解析JSON，返回默认值\n",
    "            return {\n",
    "                \"has_actor_ambiguity\": True,\n",
    "                \"ambiguity_explanation\": \"无法解析模型响应\",\n",
    "                \"identified_actors\": \"无法解析模型响应\",\n",
    "                \"role_clarification_needed\": \"无法解析模型响应\",\n",
    "                \"suggested_improvement\": \"无法解析模型响应\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"API调用失败 ({model}): {str(e)}\")\n",
    "        return {\n",
    "            \"has_actor_ambiguity\": True,\n",
    "            \"ambiguity_explanation\": f\"API调用失败: {str(e)}\",\n",
    "            \"identified_actors\": f\"API调用失败: {str(e)}\",\n",
    "            \"role_clarification_needed\": f\"API调用失败: {str(e)}\",\n",
    "            \"suggested_improvement\": f\"API调用失败: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_actor_detection(y_true: List[bool], y_pred: List[bool]) -> Dict:\n",
    "    \"\"\"\n",
    "    计算角色歧义检测的评估指标\n",
    "    \"\"\"\n",
    "    tp = fp = fn = tn = 0\n",
    "    \n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label and pred_label:\n",
    "            tp += 1\n",
    "        elif not true_label and pred_label:\n",
    "            fp += 1\n",
    "        elif true_label and not pred_label:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tn\": tn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_actor_dataset(df_subset: pd.DataFrame, model: str) -> Dict:\n",
    "    \"\"\"\n",
    "    处理数据集子集并评估模型在角色歧义检测上的性能\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"model\": model,\n",
    "        \"predictions\": [],\n",
    "        \"metrics\": {}\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing model {model}...\")\n",
    "    \n",
    "    for idx, row in df_subset.iterrows():\n",
    "        story_text = row['StoryText']\n",
    "        true_has_ambiguity = row['ActorAmbiguity']\n",
    "        \n",
    "        prompt = get_actor_ambiguity_prompt(story_text)\n",
    "        prediction = call_llm(prompt, model)\n",
    "        \n",
    "        # 确保预测结果格式正确\n",
    "        if \"has_actor_ambiguity\" not in prediction:\n",
    "            prediction[\"has_actor_ambiguity\"] = True\n",
    "        if \"ambiguity_explanation\" not in prediction:\n",
    "            prediction[\"ambiguity_explanation\"] = \"模型未提供解释\"\n",
    "        if \"identified_actors\" not in prediction:\n",
    "            prediction[\"identified_actors\"] = \"模型未识别角色\"\n",
    "        if \"role_clarification_needed\" not in prediction:\n",
    "            prediction[\"role_clarification_needed\"] = \"模型未提供角色澄清信息\"\n",
    "        if \"suggested_improvement\" not in prediction:\n",
    "            prediction[\"suggested_improvement\"] = \"模型未提供改进建议\"\n",
    "        \n",
    "        results[\"predictions\"].append({\n",
    "            \"story_id\": row['StoryID'],\n",
    "            \"story_text\": story_text,\n",
    "            \"true_has_ambiguity\": true_has_ambiguity,\n",
    "            \"pred_has_ambiguity\": prediction[\"has_actor_ambiguity\"],\n",
    "            \"ambiguity_explanation\": prediction[\"ambiguity_explanation\"],\n",
    "            \"identified_actors\": prediction[\"identified_actors\"],\n",
    "            \"role_clarification_needed\": prediction[\"role_clarification_needed\"],\n",
    "            \"suggested_improvement\": prediction[\"suggested_improvement\"]\n",
    "        })\n",
    "        \n",
    "        # 添加进度信息\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(df_subset)} samples\")\n",
    "    \n",
    "    # 计算指标\n",
    "    true_labels = [item[\"true_has_ambiguity\"] for item in results[\"predictions\"]]\n",
    "    pred_labels = [item[\"pred_has_ambiguity\"] for item in results[\"predictions\"]]\n",
    "    \n",
    "    results[\"metrics\"] = evaluate_actor_detection(true_labels, pred_labels)\n",
    "    \n",
    "    metrics = results[\"metrics\"]\n",
    "    print(f\"  Results - Precision: {metrics['precision']:.3f}, Recall: {metrics['recall']:.3f}, F1: {metrics['f1_score']:.3f}, Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actor_visualization(results: List[Dict]):\n",
    "    \"\"\"\n",
    "    创建角色歧义检测的可视化图表\n",
    "    \"\"\"\n",
    "    models = [r[\"model\"] for r in results]\n",
    "    \n",
    "    # 提取指标数据\n",
    "    precisions = [r[\"metrics\"][\"precision\"] for r in results]\n",
    "    recalls = [r[\"metrics\"][\"recall\"] for r in results]\n",
    "    f1_scores = [r[\"metrics\"][\"f1_score\"] for r in results]\n",
    "    accuracies = [r[\"metrics\"][\"accuracy\"] for r in results]\n",
    "    \n",
    "    # 创建图表\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    # 精确率和召回率\n",
    "    axes[0, 0].bar(x - width/2, precisions, width, label='Precision', alpha=0.8, color='plum')\n",
    "    axes[0, 0].bar(x + width/2, recalls, width, label='Recall', alpha=0.8, color='powderblue')\n",
    "    axes[0, 0].set_xlabel('Model')\n",
    "    axes[0, 0].set_ylabel('Score')\n",
    "    axes[0, 0].set_title('角色歧义检测 - 精确率与召回率')\n",
    "    axes[0, 0].set_xticks(x)\n",
    "    axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # F1分数\n",
    "    axes[0, 1].bar(models, f1_scores, alpha=0.8, color='rosybrown')\n",
    "    axes[0, 1].set_xlabel('Model')\n",
    "    axes[0, 1].set_ylabel('F1 Score')\n",
    "    axes[0, 1].set_title('角色歧义检测 - F1分数')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # 准确率\n",
    "    axes[1, 0].bar(models, accuracies, alpha=0.8, color='lightsteelblue')\n",
    "    axes[1, 0].set_xlabel('Model')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].set_title('角色歧义检测 - 准确率')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # 综合性能雷达图\n",
    "    angles = np.linspace(0, 2 * np.pi, 4, endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "    \n",
    "    ax_radar = plt.subplot(2, 2, 4, projection='polar')\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(models)))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        values = [precisions[i], recalls[i], f1_scores[i], accuracies[i]]\n",
    "        values = np.concatenate((values, [values[0]]))\n",
    "        ax_radar.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i])\n",
    "        ax_radar.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "    \n",
    "    ax_radar.set_xticks(angles[:-1])\n",
    "    ax_radar.set_xticklabels(['Precision', 'Recall', 'F1', 'Accuracy'])\n",
    "    ax_radar.set_ylim(0, 1)\n",
    "    ax_radar.set_title('角色歧义检测 - 综合性能对比')\n",
    "    ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('actor_ambiguity_detection_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：执行角色歧义检测分析\n",
    "    \"\"\"\n",
    "    print(\"开始角色歧义检测分析...\")\n",
    "    \n",
    "    # 准备数据集 - 从每个类别中取样\n",
    "    actor_df = df[df['ActorAmbiguity'] == True].sample(n=min(25, df[df['ActorAmbiguity'] == True].shape[0]), random_state=42)\n",
    "    non_actor_df = df[df['ActorAmbiguity'] == False].sample(n=min(25, df[df['ActorAmbiguity'] == False].shape[0]), random_state=42)\n",
    "    test_df = pd.concat([actor_df, non_actor_df]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"测试数据集大小: {test_df.shape}\")\n",
    "    print(f\"角色歧义样本数: {actor_df.shape[0]}\")\n",
    "    print(f\"无角色歧义样本数: {non_actor_df.shape[0]}\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # 对每个模型进行评估\n",
    "    for model in MODELS:\n",
    "        result = process_actor_dataset(test_df, model)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # 添加延迟以避免API限制\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # 保存结果\n",
    "    with open('actor_ambiguity_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)\n",
    "    \n",
    "    print(\"\\n角色歧义检测分析完成，结果已保存到 actor_ambiguity_results.json\")\n",
    "    \n",
    "    # 创建可视化图表\n",
    "    create_actor_visualization(all_results)\n",
    "    \n",
    "    # 打印详细结果\n",
    "    print(\"\\n详细评估结果:\")\n",
    "    for result in all_results:\n",
    "        model = result[\"model\"]\n",
    "        metrics = result[\"metrics\"]\n",
    "        \n",
    "        print(f\"\\n模型: {model}\")\n",
    "        print(f\"  精确率: {metrics['precision']:.3f}\")\n",
    "        print(f\"  召回率: {metrics['recall']:.3f}\")\n",
    "        print(f\"  F1分数: {metrics['f1_score']:.3f}\")\n",
    "        print(f\"  准确率: {metrics['accuracy']:.3f}\")\n",
    "        print(f\"  真正例: {metrics['tp']}, 假正例: {metrics['fp']}, 假负例: {metrics['fn']}, 真负例: {metrics['tn']}\")\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}