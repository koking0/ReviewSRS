{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户故事范围歧义检测分析\n",
    "\n",
    "本notebook用于分析大模型在检测用户故事范围歧义方面的性能。\n",
    "\n",
    "## 范围歧义定义\n",
    "范围歧义是指用户故事中的功能范围、边界或包含/排除的内容不明确，导致对功能的具体实现范围产生理解偏差。例如：\n",
    "- 没有明确说明功能的边界\n",
    "- 包含/排除的内容不清晰\n",
    "- 功能的深度和广度定义模糊\n",
    "- 缺乏对例外情况的处理说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置信息\n",
    "CONFIG = {\n",
    "    \"base_url\": \"https://api.zhizengzeng.com/v1/\",\n",
    "    \"api_key\": \"sk-zk20f741becece1c055c848225093b2e458662329a0f1016\"\n",
    "}\n",
    "\n",
    "# 模型列表\n",
    "MODELS = [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"claude-sonnet-4-20250514\", \n",
    "    \"gemini-2.5-flash\",\n",
    "    \"grok-3-mini\",\n",
    "    \"deepseek-chat\",\n",
    "    \"qwen3-coder-plus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "print(\"Loading user story ambiguity dataset...\")\n",
    "df = pd.read_excel(r\"data/User Story Ambiguity Dataset_A Comprehensive Research Resource/Cornelius_2025_user_story_ambiguity_dataset.xlsx\", sheet_name='User_Stories')\n",
    "\n",
    "print(f\"数据集形状: {df.shape}\")\n",
    "print(f\"范围歧义统计: {df['ScopeAmbiguity'].value_counts()}\")\n",
    "\n",
    "# 显示一些例子\n",
    "print(\"\\n范围歧义示例:\")\n",
    "scope_examples = df[df['ScopeAmbiguity'] == True][['StoryText']].head(3)\n",
    "for i, story in enumerate(scope_examples['StoryText'], 1):\n",
    "    print(f\"{i}. {story}\")\n",
    "\n",
    "print(\"\\n无范围歧义示例:\")\n",
    "non_scope_examples = df[df['ScopeAmbiguity'] == False][['StoryText']].head(3)\n",
    "for i, story in enumerate(non_scope_examples['StoryText'], 1):\n",
    "    print(f\"{i}. {story}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scope_ambiguity_prompt(story_text: str) -> str:\n",
    "    \"\"\"\n",
    "    生成用于检测用户故事范围歧义的提示词\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "**背景**: 范围歧义是指用户故事中的功能范围、边界或包含/排除的内容不明确，导致对功能的具体实现范围产生理解偏差。\n",
    "\n",
    "**角色**: 你是一名专业的自然语言处理专家，专门检测软件需求规格中的范围歧义。\n",
    "\n",
    "**任务**: 分析以下用户故事，判断其中是否存在范围歧义。\n",
    "\n",
    "**范围歧义的特征包括**:\n",
    "1. 没有明确说明功能的边界\n",
    "2. 包含/排除的内容不清晰\n",
    "3. 功能的深度和广度定义模糊\n",
    "4. 缺乏对例外情况的处理说明\n",
    "5. 输入输出范围不明确\n",
    "6. 数据处理范围界限不清\n",
    "7. 系统集成范围模糊\n",
    "8. 业务规则适用范围不明确\n",
    "\n",
    "**用户故事**: {story_text}\n",
    "\n",
    "**输出要求**:\n",
    "请按照以下JSON格式输出你的分析结果：\n",
    "{{\n",
    "    \"has_scope_ambiguity\": true/false,\n",
    "    \"ambiguity_explanation\": \"如果存在范围歧义，请解释歧义的具体内容和范围不明确的地方；如果不存在范围歧义，请说明为什么用户故事的范围是清晰的\",\n",
    "    \"scope_boundaries\": \"如果存在歧义，请指出需要明确的具体范围边界；如果不存在歧义，请说明已经明确的范围边界\",\n",
    "    \"suggested_improvement\": \"如果存在范围歧义，请提出改进建议；如果不存在范围歧义，请填写'无范围歧义，无需改进'\"\n",
    "}}\n",
    "\n",
    "**注意事项**:\n",
    "- has_scope_ambiguity的值只能是true或false\n",
    "- ambiguity_explanation应详细说明范围歧义的原因\n",
    "- scope_boundaries应指出需要明确的具体范围\n",
    "- suggested_improvement应提供具体的改进建议\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt: str, model: str) -> Dict:\n",
    "    \"\"\"\n",
    "    调用大模型API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(api_key=CONFIG[\"api_key\"], base_url=CONFIG[\"base_url\"])\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # 尝试解析JSON格式的响应\n",
    "        match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group()\n",
    "            parsed_result = json.loads(json_str)\n",
    "            return parsed_result\n",
    "        else:\n",
    "            # 如果无法解析JSON，返回默认值\n",
    "            return {\n",
    "                \"has_scope_ambiguity\": True,\n",
    "                \"ambiguity_explanation\": \"无法解析模型响应\",\n",
    "                \"scope_boundaries\": \"无法解析模型响应\",\n",
    "                \"suggested_improvement\": \"无法解析模型响应\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"API调用失败 ({model}): {str(e)}\")\n",
    "        return {\n",
    "            \"has_scope_ambiguity\": True,\n",
    "            \"ambiguity_explanation\": f\"API调用失败: {str(e)}\",\n",
    "            \"scope_boundaries\": f\"API调用失败: {str(e)}\",\n",
    "            \"suggested_improvement\": f\"API调用失败: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_scope_detection(y_true: List[bool], y_pred: List[bool]) -> Dict:\n",
    "    \"\"\"\n",
    "    计算范围歧义检测的评估指标\n",
    "    \"\"\"\n",
    "    tp = fp = fn = tn = 0\n",
    "    \n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label and pred_label:\n",
    "            tp += 1\n",
    "        elif not true_label and pred_label:\n",
    "            fp += 1\n",
    "        elif true_label and not pred_label:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tn\": tn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scope_dataset(df_subset: pd.DataFrame, model: str) -> Dict:\n",
    "    \"\"\"\n",
    "    处理数据集子集并评估模型在范围歧义检测上的性能\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"model\": model,\n",
    "        \"predictions\": [],\n",
    "        \"metrics\": {}\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing model {model}...\")\n",
    "    \n",
    "    for idx, row in df_subset.iterrows():\n",
    "        story_text = row['StoryText']\n",
    "        true_has_ambiguity = row['ScopeAmbiguity']\n",
    "        \n",
    "        prompt = get_scope_ambiguity_prompt(story_text)\n",
    "        prediction = call_llm(prompt, model)\n",
    "        \n",
    "        # 确保预测结果格式正确\n",
    "        if \"has_scope_ambiguity\" not in prediction:\n",
    "            prediction[\"has_scope_ambiguity\"] = True\n",
    "        if \"ambiguity_explanation\" not in prediction:\n",
    "            prediction[\"ambiguity_explanation\"] = \"模型未提供解释\"\n",
    "        if \"scope_boundaries\" not in prediction:\n",
    "            prediction[\"scope_boundaries\"] = \"模型未提供范围边界信息\"\n",
    "        if \"suggested_improvement\" not in prediction:\n",
    "            prediction[\"suggested_improvement\"] = \"模型未提供改进建议\"\n",
    "        \n",
    "        results[\"predictions\"].append({\n",
    "            \"story_id\": row['StoryID'],\n",
    "            \"story_text\": story_text,\n",
    "            \"true_has_ambiguity\": true_has_ambiguity,\n",
    "            \"pred_has_ambiguity\": prediction[\"has_scope_ambiguity\"],\n",
    "            \"ambiguity_explanation\": prediction[\"ambiguity_explanation\"],\n",
    "            \"scope_boundaries\": prediction[\"scope_boundaries\"],\n",
    "            \"suggested_improvement\": prediction[\"suggested_improvement\"]\n",
    "        })\n",
    "        \n",
    "        # 添加进度信息\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(df_subset)} samples\")\n",
    "    \n",
    "    # 计算指标\n",
    "    true_labels = [item[\"true_has_ambiguity\"] for item in results[\"predictions\"]]\n",
    "    pred_labels = [item[\"pred_has_ambiguity\"] for item in results[\"predictions\"]]\n",
    "    \n",
    "    results[\"metrics\"] = evaluate_scope_detection(true_labels, pred_labels)\n",
    "    \n",
    "    metrics = results[\"metrics\"]\n",
    "    print(f\"  Results - Precision: {metrics['precision']:.3f}, Recall: {metrics['recall']:.3f}, F1: {metrics['f1_score']:.3f}, Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scope_visualization(results: List[Dict]):\n",
    "    \"\"\"\n",
    "    创建范围歧义检测的可视化图表\n",
    "    \"\"\"\n",
    "    models = [r[\"model\"] for r in results]\n",
    "    \n",
    "    # 提取指标数据\n",
    "    precisions = [r[\"metrics\"][\"precision\"] for r in results]\n",
    "    recalls = [r[\"metrics\"][\"recall\"] for r in results]\n",
    "    f1_scores = [r[\"metrics\"][\"f1_score\"] for r in results]\n",
    "    accuracies = [r[\"metrics\"][\"accuracy\"] for r in results]\n",
    "    \n",
    "    # 创建图表\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    # 精确率和召回率\n",
    "    axes[0, 0].bar(x - width/2, precisions, width, label='Precision', alpha=0.8, color='lightcoral')\n",
    "    axes[0, 0].bar(x + width/2, recalls, width, label='Recall', alpha=0.8, color='lightblue')\n",
    "    axes[0, 0].set_xlabel('Model')\n",
    "    axes[0, 0].set_ylabel('Score')\n",
    "    axes[0, 0].set_title('范围歧义检测 - 精确率与召回率')\n",
    "    axes[0, 0].set_xticks(x)\n",
    "    axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[0, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # F1分数\n",
    "    axes[0, 1].bar(models, f1_scores, alpha=0.8, color='gold')\n",
    "    axes[0, 1].set_xlabel('Model')\n",
    "    axes[0, 1].set_ylabel('F1 Score')\n",
    "    axes[0, 1].set_title('范围歧义检测 - F1分数')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # 准确率\n",
    "    axes[1, 0].bar(models, accuracies, alpha=0.8, color='mediumseagreen')\n",
    "    axes[1, 0].set_xlabel('Model')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].set_title('范围歧义检测 - 准确率')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # 综合性能雷达图\n",
    "    angles = np.linspace(0, 2 * np.pi, 4, endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "    \n",
    "    ax_radar = plt.subplot(2, 2, 4, projection='polar')\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(models)))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        values = [precisions[i], recalls[i], f1_scores[i], accuracies[i]]\n",
    "        values = np.concatenate((values, [values[0]]))\n",
    "        ax_radar.plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i])\n",
    "        ax_radar.fill(angles, values, alpha=0.25, color=colors[i])\n",
    "    \n",
    "    ax_radar.set_xticks(angles[:-1])\n",
    "    ax_radar.set_xticklabels(['Precision', 'Recall', 'F1', 'Accuracy'])\n",
    "    ax_radar.set_ylim(0, 1)\n",
    "    ax_radar.set_title('范围歧义检测 - 综合性能对比')\n",
    "    ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('scope_ambiguity_detection_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：执行范围歧义检测分析\n",
    "    \"\"\"\n",
    "    print(\"开始范围歧义检测分析...\")\n",
    "    \n",
    "    # 准备数据集 - 从每个类别中取样\n",
    "    scope_df = df[df['ScopeAmbiguity'] == True].sample(n=min(30, df[df['ScopeAmbiguity'] == True].shape[0]), random_state=42)\n",
    "    non_scope_df = df[df['ScopeAmbiguity'] == False].sample(n=min(30, df[df['ScopeAmbiguity'] == False].shape[0]), random_state=42)\n",
    "    test_df = pd.concat([scope_df, non_scope_df]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"测试数据集大小: {test_df.shape}\")\n",
    "    print(f\"范围歧义样本数: {scope_df.shape[0]}\")\n",
    "    print(f\"无范围歧义样本数: {non_scope_df.shape[0]}\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # 对每个模型进行评估\n",
    "    for model in MODELS:\n",
    "        result = process_scope_dataset(test_df, model)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # 添加延迟以避免API限制\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # 保存结果\n",
    "    with open('scope_ambiguity_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)\n",
    "    \n",
    "    print(\"\\n范围歧义检测分析完成，结果已保存到 scope_ambiguity_results.json\")\n",
    "    \n",
    "    # 创建可视化图表\n",
    "    create_scope_visualization(all_results)\n",
    "    \n",
    "    # 打印详细结果\n",
    "    print(\"\\n详细评估结果:\")\n",
    "    for result in all_results:\n",
    "        model = result[\"model\"]\n",
    "        metrics = result[\"metrics\"]\n",
    "        \n",
    "        print(f\"\\n模型: {model}\")\n",
    "        print(f\"  精确率: {metrics['precision']:.3f}\")\n",
    "        print(f\"  召回率: {metrics['recall']:.3f}\")\n",
    "        print(f\"  F1分数: {metrics['f1_score']:.3f}\")\n",
    "        print(f\"  准确率: {metrics['accuracy']:.3f}\")\n",
    "        print(f\"  真正例: {metrics['tp']}, 假正例: {metrics['fp']}, 假负例: {metrics['fn']}, 真负例: {metrics['tn']}\")\n",
    "\n",
    "# 执行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}